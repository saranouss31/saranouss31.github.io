My name is Saran Ousseini. I am a 22 years student from Southern New Hampshire Univeristy. I will be graduation at the ed of April with my Bachelor in Science in Biology. During my time at Souther New Hampshire University, I was able to take coding class called Bio-informatic. 
This class introduced me to R-Studio, though me the basics of coding. 
I was able to explore more about the new wave of science with is the mix of biology and informatics/coding. This class uses technlogy like computers,  databases, uses  math, and statistics to analyze, collect, organize, and store large amounts of biological information. Through this class I was able too observe biological data works that could have taken weeks to archieve, be done in less than a minute.
 Some of the project I was able to work one are:

My first project is called Penguin Analysis. This is the project that introduced me to the basics of bioinformatics 
We used Palmer Penguin data set to learn how R studio works. We ran analysis, and ran different codes. We used small subset of 44 pensguin. This analysis can be found [Here](https://saranouss31.github.io/BioStatisticsAnalysis/PalmerPenguinsAnalysis.html) 

My second project focused on practicing technical analysis skills, such documenting and communicating analysis, conducting exploratory analysis, generating hypotheses, and connecting exploratory analysis to hypotheses. In this project, I made a new notebook and wrote an abstract and an introduction, annotated exploratory analysis with a narrative, continuing exploratory analysis, generating hypotheses, and using Git to push changes to a GitHub repository. All of this was done by using the datas from Bird Bath, and running different codes in order to make chart, graph and finding connection within all of the data acquired, This analysis can be found [Here](https://github.com/saranouss31/BioStatisticsAnalysis/blob/12e4ef7759c7a2e7f0d19c07d0f4c464e6a5c0ba/bird_bathsSaran.html)

My third project was a group prject, it consisted of an Introduction, Part I, Part II, III, IV and V. 
Through out this notebook, we started by the introduction. In the introduction, we had 10 challenges. Through this 10 challenges, we were able to create list of nucleotide, we used function such as sample() which helped create randome genome from the characters in the nucleotide list. We also use function paste() as well as collapse = "" to collapse the random genome into one string of nucleotide. In the introduction we learned how to use the function set.seed() which help set a seed of a random number generator, this made our result reproducible. We were also introduced to for loop to repeat set of simple instruction.
 Next, we started Part I. Part 1 had 5 challenges, during this challenges, we learned to write reusable code using functions. In addition, we developed skills in working with genomes, such as identifying patterns of a specific length and counting their occurrences within a genome. These two tasks were important in identifying the Replication Origin. Followeing Part 1, we talked Part 2, which consisted of 2 challenges. This challenges gave us the capability to scan a genome and identify frequent "near" k-mers, as well as their reverse-complements, which can be defined as genetic substrings that serve as signals for DNA polymerase replication.
Lastly, we tackled Part III. This part was combination of all the other codes we worked on, and function we created, to finally be able to create the functions clump_finding(). This analysis can be found [HERE]



